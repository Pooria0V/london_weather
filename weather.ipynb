{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nLfql13zzMmI"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.metrics import mean_squared_error\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5tUywlbzMmL"
      },
      "source": [
        "# import dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3GrnwL4qzMmM"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('london_weather.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6sZcNCozMmM"
      },
      "source": [
        "# fill missing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uN0bT7oAzMmM",
        "outputId": "6e358c74-9c57-4fce-fff9-9c46f1001323"
      },
      "outputs": [],
      "source": [
        "# df = df.fillna(1)\n",
        "df = df.fillna(method='ffill')\n",
        "# df_filled = df.interpolate(method='linear')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDIq8OqDzMmN"
      },
      "source": [
        "# split dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "dJCnzvZOzMmN"
      },
      "outputs": [],
      "source": [
        "x = df.drop(columns=['max_temp','snow_depth'], axis=1)\n",
        "y = df['max_temp']\n",
        "\n",
        "x = np.array(x)\n",
        "y = np.array(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3itCBlrzMmN",
        "outputId": "5160df18-e703-45d9-f1d7-a9140574e8d7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1535,)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x, x_test_main, y, y_test_main = train_test_split(x, y, test_size=0.1, random_state=42)\n",
        "# y_train = y_train.astype(int)\n",
        "# y_test = y_test.astype(int)\n",
        "y_test_main.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFw_ij70zMmO"
      },
      "source": [
        "# normalizing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQI6HxIAzMmO",
        "outputId": "a785d77f-7551-4791-f41f-51bc9efc26f2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.36609191, 0.33333333, 0.86875   , 0.82352941, 0.67213115,\n",
              "       0.6568915 , 0.        , 0.79683973])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "x = scaler.fit_transform(x)\n",
        "x_test_main = scaler.fit_transform(x_test_main)\n",
        "x[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbW7QZwFzMmP"
      },
      "source": [
        "# pca"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "hYmkPOLazMmP"
      },
      "outputs": [],
      "source": [
        "# from sklearn.decomposition import PCA\n",
        "\n",
        "# pca = PCA(n_components=8)\n",
        "\n",
        "# x = pca.fit_transform(X=x)\n",
        "# x_test_main = pca.transform(X=x_test_main)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8jDXd0YzMmP"
      },
      "source": [
        "\n",
        "# define model 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "SMyC_bu5zMmP"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# model = keras.Sequential()\n",
        "# model.add(keras.layers.Input(shape=(8,)))\n",
        "# model.add(keras.layers.Dense(units=32, activation='relu'))\n",
        "# model.add(keras.layers.Dense(units=32, activation='sigmoid'))\n",
        "# model.add(keras.layers.Dense(units=1))\n",
        "# model.compile(optimizer=tf.optimizers.Adam(), loss='mean_squared_error', metrics=['accuracy'])\n",
        "# # model.compile(optimizer=tf.optimizers.Adam(), loss=tf.losses.mean_squared_error, metrics=['accuracy'])\n",
        "# model.fit(x, y, epochs=20, batch_size=64, validation_data=(x_test_main, y_test_main))\n",
        "# y_pred = model.predict(x_test_main)\n",
        "# mse = mean_squared_error(y_true=y_test_main, y_pred=y_pred)\n",
        "# mse\n",
        "# # 12.187250703339979 => mean_squared_error with scaler and pca\n",
        "# # 10.015396159320842 => mean_squared_error with scaler and without pca\n",
        "# # 42.39169921336769 => mean_squared_error without scaler and without pca\n",
        "# # 10.933645420023264 => mean_squared_error without column snow_depth and without pca and with scaler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yRGp8HPzMmQ"
      },
      "source": [
        "# define model 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFy6jrAJzMmQ",
        "outputId": "cd7b2778-0250-4455-fa17-fa9f90ecd22d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(5.365472610540216, 4.892028082248992)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "kf = KFold(n_splits=6)\n",
        "def model_creator():\n",
        "    model = keras.Sequential()\n",
        "    model.add(keras.layers.Input(shape=(8,)))\n",
        "    model.add(keras.layers.Dense(units=448, activation='relu'))\n",
        "    model.add(keras.layers.Dense(units=320, activation='relu'))\n",
        "    model.add(keras.layers.Dense(units=32, activation='relu'))\n",
        "    model.add(keras.layers.Dense(units=1, activation='linear'))\n",
        "    model.compile(optimizer=tf.optimizers.Adam(), loss='mean_squared_error', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "mse_list = []\n",
        "for train, validation in kf.split(x, y):\n",
        "\n",
        "    # x_train = x_train_main[train]\n",
        "    # y_train = y_train_main[train]\n",
        "\n",
        "    # x_test = x_train_main[validation]\n",
        "    # y_test = x_train_main[validation]\n",
        "\n",
        "    # x_train, x_test = x[train], x[validation]\n",
        "    # y_train, y_test = y[train], y[validation]\n",
        "\n",
        "    x_train = x[train]\n",
        "    x_test = x[validation]\n",
        "    y_train = y[train]\n",
        "    y_test = y[validation]\n",
        "\n",
        "    model = model_creator()\n",
        "    model.fit(x_train, y_train, epochs=20, batch_size=64, validation_data=(x_test, y_test), verbose=0)\n",
        "\n",
        "    y_pred = model.predict(x_test)\n",
        "\n",
        "    mse_list.append(mean_squared_error(y_test, y_pred))\n",
        "\n",
        "# mse_list\n",
        "\n",
        "y_pred_main = model.predict(x_test_main)\n",
        "mse_main = mean_squared_error(y_test_main, y_pred_main)\n",
        "mse_main, np.mean(mse_list)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# # 6.304961665296364 => mean_squared_error with scaler and without pca\n",
        "# #(7.039170778006721, 5.531378233763437) => mean_squared_error with random search parameters\n",
        "# (6.022063032004108, 5.339298581649459)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ue_42zAQzMmQ"
      },
      "source": [
        "# best parameters model 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Z7gU6OOPzlEb"
      },
      "outputs": [],
      "source": [
        "# ! pip install keras-tuner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "BF0mO2obzMmQ"
      },
      "outputs": [],
      "source": [
        "# from keras_tuner import RandomSearch\n",
        "# # from keras_tuner import GridSearch\n",
        "\n",
        "# # Define your model inside a function with hyperparameters as input\n",
        "# def build_model(hp):\n",
        "#     model = keras.Sequential()\n",
        "\n",
        "#     # Tune number of layers (from 2 to 4)\n",
        "#     for i in range(hp.Int('num_layers', 2, 4)):\n",
        "#         model.add(keras.layers.Dense(units=hp.Int('units_' + str(i), min_value=32, max_value=512, step=32),\n",
        "#                                      activation=hp.Choice('activation_' + str(i), ['relu', 'tanh'])))\n",
        "\n",
        "#     model.add(keras.layers.Dense(1, activation='softmax'))\n",
        "\n",
        "#     # Tune optimizer learning rate\n",
        "#     model.compile(\n",
        "#         optimizer=keras.optimizers.Adam(\n",
        "#             hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])\n",
        "#         ),\n",
        "#         loss='mean_squared_error',\n",
        "#         metrics=['mean_squared_error'])\n",
        "\n",
        "#     return model\n",
        "\n",
        "# # Create the tuner object\n",
        "# tuner = RandomSearch(\n",
        "#     build_model,\n",
        "#     objective='val_mean_squared_error', # Metric to optimize\n",
        "#     max_trials=5,             # Number of random configurations to try\n",
        "#     executions_per_trial=3,    # Number of models to train for each trial (for robustness)\n",
        "#     directory='my_dir',        # Directory to save logs and checkpoints\n",
        "#     project_name='random_search'\n",
        "#     # project_name='grid_search'\n",
        "# )\n",
        "\n",
        "\n",
        "\n",
        "# # Start the search\n",
        "# tuner.search(x, y, epochs=10, validation_data=(x_test_main, y_test_main))\n",
        "\n",
        "# # Get the best hyperparameters and the best model\n",
        "# best_hps = tuner.get_best_hyperparameters()[0]\n",
        "# best_model = tuner.get_best_models()[0]\n",
        "\n",
        "# # Summary of the best model\n",
        "# best_model.summary()\n",
        "\n",
        "# # print(f\"Best number of units: {best_hps.get('units')}\")\n",
        "# # print(list(best_hps))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "sQNFQ-6S176Y"
      },
      "outputs": [],
      "source": [
        "# random search model:\n",
        "\n",
        "# ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
        "# ┃ Layer (type)                         ┃ Output Shape                ┃         Param # ┃\n",
        "# ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
        "# │ dense (Dense)                        │ (None, 448)                 │           4,032 │\n",
        "# ├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
        "# │ dense_1 (Dense)                      │ (None, 320)                 │         143,680 │\n",
        "# ├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
        "# │ dense_2 (Dense)                      │ (None, 32)                  │          10,272 │\n",
        "# ├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
        "# │ dense_3 (Dense)                      │ (None, 1)                   │              33 │\n",
        "# └──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
        "#  Total params: 158,017 (617.25 KB)\n",
        "#  Trainable params: 158,017 (617.25 KB)\n",
        "#  Non-trainable params: 0 (0.00 B)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLjQxBrnzMmR"
      },
      "source": [
        "# best parameters model 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "nnlFWuL9zMmR"
      },
      "outputs": [],
      "source": [
        "# from sklearn.model_selection import RandomizedSearchCV\n",
        "# from keras.wrappers.scikit_learn import KerasClassifier\n",
        "\n",
        "# # Define a function to create your Keras model\n",
        "# def create_model(activation='relu', hidden_layer_size=32, dropout_rate=0.2):\n",
        "#     # ... (Your model architecture)\n",
        "\n",
        "#     return model\n",
        "\n",
        "# # Create a KerasClassifier instance\n",
        "# model = KerasClassifier(build_fn=create_model, verbose=0)\n",
        "\n",
        "# # Define the hyperparameter search space\n",
        "# param_dist = {\n",
        "#     'activation': ['relu', 'tanh', 'sigmoid'],\n",
        "#     'hidden_layer_size': [16, 32, 64, 128],\n",
        "#     'dropout_rate': [0.2, 0.3, 0.4, 0.5]\n",
        "# }\n",
        "\n",
        "# # Create a RandomizedSearchCV object\n",
        "# random_search = RandomizedSearchCV(estimator=model, param_distributions=param_dist, n_iter=10, cv=3)\n",
        "\n",
        "# # Fit the random search to your data\n",
        "# random_search.fit(X_train, y_train)\n",
        "\n",
        "# # Get the best parameters and model\n",
        "# best_params = random_search.best_params_\n",
        "# best_model = random_search.best_estimator_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ENMCIEbzMmR"
      },
      "source": [
        "# best parameters model 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "c9aPjJsJzMmS"
      },
      "outputs": [],
      "source": [
        "# def get_reg(meta, hidden_layer_sizes, dropout, active='relu'):\n",
        "#     n_features_in_ = meta[\"n_features_in_\"]\n",
        "#     model = keras.models.Sequential()\n",
        "#     model.add(keras.layers.Input(shape=(n_features_in_,)))\n",
        "#     for hidden_layer_size in hidden_layer_sizes:\n",
        "#         model.add(keras.layers.Dense(hidden_layer_size, activation=active))\n",
        "#         model.add(keras.layers.Dropout(dropout))\n",
        "#     model.add(keras.layers.Dense(1))\n",
        "#     return model\n",
        "# from scikeras.wrappers import KerasRegressor\n",
        "\n",
        "\n",
        "# reg = KerasRegressor(\n",
        "#     model=get_reg,\n",
        "#     loss=\"mse\",\n",
        "#     metrics=[keras.metrics.R2Score],\n",
        "#     hidden_layer_sizes=(100,),\n",
        "#     dropout=0.5,\n",
        "# )\n",
        "# reg.fit(x_train, y_train)\n",
        "# from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# param_grid = {\n",
        "#     'alpha': [0.1, 1.0, 10.0, 100.0, 1000.0],\n",
        "#     'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']\n",
        "# }\n",
        "# rs = RandomizedSearchCV(estimator=reg, param_distributions=param_grid, cv=3, n_iter=20)\n",
        "\n",
        "# rs.fit(x_train, y_train)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRfGcOWI5Hly"
      },
      "source": [
        "# best parameters model 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "YyyuW1gJ5KYX"
      },
      "outputs": [],
      "source": [
        "# ! pip install tensorflow scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "5Zfbt4ag5TMl"
      },
      "outputs": [],
      "source": [
        "# # Required libraries\n",
        "# import numpy as np\n",
        "# from sklearn.model_selection import GridSearchCV\n",
        "# from tensorflow.keras.models import Sequential\n",
        "# from tensorflow.keras.layers import Dense\n",
        "# from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
        "# from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# # Function to create Keras model\n",
        "# def create_model(optimizer='adam', neurons=32, activation='relu'):\n",
        "#     # Define the model\n",
        "#     model = Sequential()\n",
        "#     model.add(Dense(neurons, input_dim=10, activation=activation))  # Example input_dim=10\n",
        "#     model.add(Dense(1))  # Output layer (regression)\n",
        "\n",
        "#     # Compile the model\n",
        "#     model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
        "#     return model\n",
        "\n",
        "# # Wrap the model using KerasRegressor\n",
        "# keras_regressor = KerasRegressor(build_fn=create_model, verbose=0)\n",
        "\n",
        "# # Define the hyperparameter grid to search\n",
        "# param_grid = {\n",
        "#     'batch_size': [10, 20],\n",
        "#     'epochs': [10, 50],\n",
        "#     'optimizer': ['adam', 'rmsprop'],\n",
        "#     'neurons': [16, 32, 64],\n",
        "#     'activation': ['relu', 'tanh'],\n",
        "# }\n",
        "\n",
        "# # Create the GridSearchCV object\n",
        "# grid = GridSearchCV(estimator=keras_regressor, param_grid=param_grid, scoring='neg_mean_squared_error', cv=3)\n",
        "\n",
        "\n",
        "\n",
        "# # Fit the grid search\n",
        "# grid_result = grid.fit(x, y)\n",
        "\n",
        "# # Summarize results\n",
        "# print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
